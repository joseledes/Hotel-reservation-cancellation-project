# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ttrkTnvI93b8UhbdI1hTz-ifvKPnQyzh



Introducción:
El dataset elegido se trata de las reservas de una cadena hotelera, donde se intentarà analizar el motivo de la gran cantidad de cancelaciones que se dan en un perìodo de tiempo y sugerir medidas que se pueden implementar para reducir las cancelaciones y asegurar los ingresos. Este dataset se obtuvo del depósito de datos de Kaggle. Kaggle es un repositorio público en línea de datos que permite a los usuarios acceder y analizar datos tomados de diferentes fuentes. Este conjunto de datos incluye información sobre dos tipos diferentes de hoteles (ciudad y resort) y si se cancelaron las reservas. Cada registro es una reserva de hotel e incluye información como la fecha de llegada, las noches indicadas, el número de adultos/niños alojados, cantidad de solicitudes, etc.

Problema planteado y descripción del proyecto.
El CEO de una importante empresa hotelera descubre un problema en el contrato con las agencias de marketing. El contrato establece un costo mensual fijo y un costo variable basado en las reservas realizadas. El CEO se da cuenta de que están pagando por reservas canceladas y sospecha que las cancelaciones son frecuentes. El gerente financiero admite que no han verificado si ha habido cambios en la tasa de cancelación desde que se firmó el contrato, por lo que se intentará analizar estos costos. Las cancelaciones de reservas de hoteles pueden resultar perjudiciales para los propietarios de empresas; aunque a veces existen motivos genuinos para que los invitados lo hagan. Estas cancelaciones de último momento pueden provocar una pérdida de ingresos a menos que se tomen algunas medidas para mitigar la pérdida. El propósito de este proyecto es analizar datos de reservas de hoteles, investigar cancelaciones y sus patrones subyacentes; y sugerir medidas que se pueden implementar para reducir las cancelaciones y asegurar los ingresos.

Descripciòn de los campos:
hotel = Hotel Canceled = Cancelado lead time = Plazo De Entrega arrival_date_year = Fecha De Llegada Año arrival_date_month = Fecha De Llegada Mes arrival_date_week_number = Fecha De Llegada Número De Semana arrival_date_day_of_month = Fecha De Llegada Día De Mes stays_in_weekend_nights = Estancia En Noches De Fin De Semana stays_in_week_nights = Estancia En Noches De Semana adults = Adultos children = Niños babies = Bebés meal = Comida country = País market_segment = Segmento Del Mercado distribution_channel = Canal De Distribución is_repeated_guest = Es Huésped Repetido previous_cancellations = Cancelaciones Anteriores previous_bookings_not_canceled = Reservas Anteriores No Canceladas reserved_room_type = Tipo De Habitación Reservada assigned_room_type = Tipo De Habitación Asignada booking_changes = Cambios En La Reserva agent = Agente company = Compañía days_in_waiting_list = Dìas En La Lista De Espera customer_type = Tipo De Cliente adr = Sigla para clasificar riesgo de cancelación required_car_parking_spaces = Plaza De Aparcamiento Obligatoria total_of_special_requests = Total De Solicitudes Especiales reservation_status = Estado De Reserva reservation_status_date = Fecha De Estado De Reserva

Preguntas
1 - Cuàl es el porcentaje de cancelaciones en toda la cadena hotelera? 2 - En què tipo de hotel suceden con mayor frecuencia estas cancelaciones? 3 - En que mes del año se dan la mayor cantidad de cancelaciones? 4 - De què continente es el mayor porcentaje de cancelaciones? y de que paises? 5 - Cuàl es la tarifa media (ADR) para las cancelaciones y las reservas cumplidas? 6 - Según el gráfico del punto 4, que metodología de reservas utilizan para las reservas de Portugal? 7 - Hay muchas cancelaciones de agencias?

Posibles hipótesis
1 - A apartir del mes de enero según el gráfico n°5 se da un ascenso en la cantidad de reservas hasta el mes de agosto, donde a este ascenso también lo acompaña una tendencia de cancelaciones. En el gráfico se observa una ligera tendencia de ADR más altos en la linea de cancelaciones. Podríamos suponer que esa tendencia a cancelaciones se debe a los ADR más altos. 2 - Según el problema panteado por el CEO, el mayor porcentaje de cancelaciones se esta dando con los posibles huéspedes de Portugal, y la mayoría de estos son contratados mediante agencias. Por lo que posiblemente se le este pagando un costo variable por las reservas canceladas.

Posibles soluciones
1 - Requerir depósitos con tarjeta de crédito/débito/efectivo, para evitar futuras cancelaciones. 2 - Ofrecer tarifas bajas/descuentos para reservas directas, y bajar la cantidad de reservas realizadas por agencias y así bajar el costo variable por reservas. 3 - Rever el contrato para no pagar el costo de reservas canceladas. 4 - Adoptar una estrategia cautelosa de overbooking.

Storytelling
Introducción al Proyecto: El proyecto se centra en la predicción de cancelaciones de reservas de hotel y cómo esto puede ser valioso para la industria hotelera.

Obtención del Conjunto de Datos: El conjunto de datos utilizado en el proyecto se obtiene de Kaggle y contiene información sobre reservas de hotel, incluyendo datos demográficos de clientes, detalles de la reserva y otros factores relevantes.

Exploración del Conjunto de Datos y limpieza: Se realiza una exploración detallada del conjunto de datos para comprender su estructura y características clave para luego evaluar los datos relevantes y realizar la limpieza de los datos faltantes o no relevantes.

Proceso de Aprendizaje Automático: Se describe el proceso de entrenamiento del modelo, donde se utilizan librerías de Sklearn para evaluar los modelos.

División de Entrenamiento/Prueba: Se divide el conjunto de datos en conjuntos de entrenamiento y prueba para evaluar el modelo.

Evaluación del Rendimiento del Modelo: Se evalúa el rendimiento del modelo utilizando métricas como precisión, puntuación F1.
"""

from google.colab import drive

drive.mount("mi_carpeta")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier
from IPython import display
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

df = pd.read_excel('/content/mi_carpeta/MyDrive/Setdatos/hotel_bookings2.xlsx')

"""### Se realiza copia del DS para una mejor manipulación"""

data_for_fit = df.copy() #DF para entrenamiento

df_graf = data_for_fit.copy() # DF para consultas

from sklearn.model_selection import cross_val_score

# Realizar validación cruzada
scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')

print("Puntajes de validación cruzada:", scores)
print("Promedio de precisión:", scores.mean())

"""### Transformando los meses en números

- Se transformo los meses de STR a números, para luego concatenarlo con "arrival_date_year" + "Date_MonthOK" + "arrival_date_day_of_motn" y configurarlo como Datetime y utilizarlo para el análisis.
- Se creo la columna "Stays" donde se suman las reservas de los días de la semana como las del fin de semana.
"""

dic_codi_fecha = {"January": 1, "February": 2,"March": 3, "April": 4,"May": 5, "June": 6,"July": 7, "August": 8,"September": 9, "October": 10,"November": 11, "December": 12}
df_graf["Date_MonthOK"] = df_graf["arrival_date_month"].map(dic_codi_fecha)
df_graf['Date_OK'] = df_graf['arrival_date_year'].astype(str) + df_graf['Date_MonthOK'].astype(str).str.zfill(2) + df['arrival_date_day_of_month'].astype(str).str.zfill(2)

df_graf['stays']= df_graf['stays_in_weekend_nights']+df_graf['stays_in_week_nights']
df_graf['reservation_status_date'] = pd.to_datetime(df_graf['reservation_status_date'])
df_graf['Date_OK'] = pd.to_datetime(df_graf['Date_OK'])

"""Se reemplazaron los NULL por ceros, ya que se considera que tanto los NULL como los datos son importantes en el DF. Según la problematica planteada, los NULL representan a reservas realizadas sin agencia de por medio, lo cual es importante para el training."""

df_graf.drop(["reservation_status_date"], axis=1, inplace=True)
df_graf.fillna(value = 0, inplace=True)

"""Se reemplazaron los NA de la columna "children", se considera que esta variable es importante en el caso de las cancelaciones de reservas. Se reemplazó con 0, suponiendo que no se completo el campo ya que los huespedes no tenian niños."""

df_graf['children'].replace('NA', 0, inplace=True)

df_graf.info()

for col in df_graf.describe(include = 'object').columns:
    print(col)
    print(df_graf[col].unique())
    print('-'*50)

"""### 1 - Cuál es el porcentaje de cancelaciones en toda la cadena hotelera?

Como se visualiza en el gràfico, hay un alto grado de cancelaciones de las reservas.

"""

Porc_Cancel = df_graf['is_canceled'].value_counts()
plt.figure(figsize=(4, 3))
plt.pie(Porc_Cancel, labels=['Not Canceled','Canceled' ], autopct='%.1f%%', startangle=90)
plt.show()

"""### 2 - En qué tipo de hotel suceden con mayor frecuencia estas cancelaciones?

La mayor cantidad de cancelaciones se dan en la clase City Hotel
"""

CompH_C= sns.countplot(x = 'hotel', hue = 'is_canceled', data = df_graf, palette = 'Blues')
plt.title('Tipo de hoteles VS cancelaciones')
plt.xlabel('Hotel')
plt.ylabel('Reservaciones')
plt.legend(['Not canceled','canceled'])
plt.show()

"""Podemos ver que las proporciones de reservas canceladas vs no canceladas son diferentes para los diferentes tipos de hoteles. Para el city hotel, el 58,2% de las reservas no se cancelaron frente al 41,7% de las reservas que se cancelaron, formando una mayoría. En cambio, para el hotel resort, el 72,3% de las reservas no se cancelaron mientras que el 27,7% de las reservas se cancelaron. Aunque, la mayoría de las reservas no fueron canceladas para ambos hoteles."""

resort_hotel = df_graf[df_graf['hotel'] == 'Resort Hotel']
resort_hotel['is_canceled'].value_counts(normalize = True)

city_hotel = df_graf[df_graf['hotel'] == 'City Hotel']
city_hotel['is_canceled'].value_counts(normalize = True)

"""### 3 - En que mes se dan la mayor cantidad de cancelaciones?


En el mes de Agosto el porcentaje de cancelaciones es mayor.
"""

df_graf['month'] = df_graf['arrival_date_month']
plt.figure(figsize = (20,6))
res_mon = sns.countplot(x = 'arrival_date_month', hue = 'is_canceled', data = df_graf, palette = 'bright', order= ['January','February','March','April','May','June','July','August','September','October','November','December'])
legend_labels,_ = res_mon.get_legend_handles_labels()
res_mon.legend(bbox_to_anchor = (1,1))
plt.title('Status de reservación por mes')
plt.xlabel('Mes')
plt.ylabel('Q reservaciones')
plt.legend(['not canceled','canceled'])
plt.show()

"""### 4 - De qué continente es el mayor porcentaje de cancelaciones? y de que paises?

Sin duda el mayor porcentaje de cancelaciones se da en Paises Europeos.
Principalmente Portugal(PRT) tiene el mayor porcentaje de cancelaciones, seguido por Gran Bretaña(GBR) y luego por España(ESP)
"""

continent_cancel = df_graf[df_graf['is_canceled'] == 1]
continent = continent_cancel['Continent'].value_counts()[:5]
plt.figure(figsize = (10,5))
plt.title('Continente con mayor % de cancelaciones')
plt.pie(continent, autopct = "%.2f%%", labels = continent.index)
plt.show()

country_cancel = df_graf[df_graf['is_canceled'] == 1]
top_10_country = country_cancel['country_name'].value_counts()[:10]
plt.figure(figsize = (20,8))
plt.title('Top 10 de paises con mayor cancelaciòn')
plt.pie(top_10_country, autopct = '%.2f%%', labels = top_10_country.index)
plt.show()

"""### 5 - Cuàl es la tarifa media (ADR) para las cancelaciones y las reservas cumplidas?

Podemos visualizar en el seguiente gràfico que en los ADR màs altos se dan la mayor cantidad de cancelaciones.

"""

cancelled_df_adr = country_cancel.groupby('Date_OK')[['adr']].mean()
cancelled_df_adr.reset_index(inplace = True)
cancelled_df_adr.sort_values('Date_OK', inplace=True)

not_cancelled_data = df_graf[df_graf['is_canceled'] == 0]
not_cancelled_df_adr = not_cancelled_data.groupby('Date_OK')[['adr']].mean()
not_cancelled_df_adr.reset_index(inplace = True)
not_cancelled_df_adr.sort_values('Date_OK',inplace=True)

plt.figure(figsize = (20,6))
plt.title('Tarifa media por día')
plt.plot(not_cancelled_df_adr['Date_OK'], not_cancelled_df_adr['adr'], label = 'not cancelled')
plt.plot(cancelled_df_adr['Date_OK'], cancelled_df_adr['adr'], label = 'cancelled')
plt.legend()
plt.show()

"""Para los hoteles resort, la tarifa diaria promedio es más cara durante agosto, julio y septiembre.

En los hoteles urbanos, la tarifa media diaria es más cara durante los meses de agosto, julio, junio y mayo.
"""

plt.figure(figsize=(12,6))
sns.lineplot(x='arrival_date_month', y='adr', hue='hotel', data= df_graf)
plt.show()

"""La mayor cantidad de estadías van de 1 a 4 días."""

df_graf['stays']= df_graf['stays_in_weekend_nights']+df_graf['stays_in_week_nights']
plt.figure(figsize=(18,5))
sns.countplot(x=df_graf['stays'])
plt.show()

df_replace = df_graf

df_replace['is_canceled'] = df_replace['is_canceled'].replace(0,'No')
df_replace['is_canceled'] = df_replace['is_canceled'].replace(1,'Yes')

(sns.FacetGrid(df, hue = 'is_canceled',
             height = 6,
             xlim = (0,500))
    .map(sns.kdeplot, 'lead_time', shade = True)
    .add_legend());

"""### Según el gráfico del punto 4, que metodología de reservas utilizan para las reservas de Portugal?

Según los gráficos la mayor cantidad de cancelaciones fueron del canal TA/TO (plataformas de reservas online)
"""

portugal_canceled = df_graf[(df_graf['is_canceled'] == "Yes") & (df_graf['country_name'] == 'Portugal')]
distrib_channel = portugal_canceled['distribution_channel'].value_counts()
plt.title('Cancelaciones de Portugal según canal')
plt.bar(['TA/TO', 'Direct', 'Corporate','Undefined', 'GDS'], portugal_canceled['distribution_channel'].value_counts())
plt.show()

"""Explorando las cancelaciones por TA/TO, vemos también que la mayor cantidad se dan principalmente en 3 segmentos:  
Groups, Offline TA/TO y Online TA.
"""

portugal_canceled_TATO = df_graf[(df_graf['is_canceled'] == "Yes") & (df['country_name'] == 'Portugal') & (df_graf['distribution_channel'] == 'TA/TO')]
mark_segment = portugal_canceled_TATO['market_segment'].value_counts()
print (mark_segment)
plt.figure(figsize=(18,5))
plt.title('Cancelaciones Portugal según tipo de reserva')
plt.bar(['Groups','Offline TA/TO','online TA','Corporate', 'Complementary','Direct','Aviation'], portugal_canceled_TATO['market_segment'].value_counts())
plt.show()

"""### Hay muchas cancelaciones de agencias?

Según el conteo de cancelaciones de agencias, algunas agencias en particular tiene mucha cantidad de cancelaciones.
por ejemplo, del siguiente listado que solo contiene las primeras 5 agencias tenemos casí la mitad de cancelaciones de Portugal.  
1.0      5213
240.0    2394
9.0      1172
6.0      1019
19.0      780
"""

portugal_canceled_TATO = df_graf[(df_graf['is_canceled'] == "Yes") & (df_graf['country_name'] == 'Portugal') & (df_graf['distribution_channel'] == 'TA/TO')]
portugal_agent = portugal_canceled_TATO['agent'].value_counts()[:10]
portugal_agent

plt.figure(figsize=(18,5))
sns.countplot(data=portugal_canceled_TATO, x=portugal_canceled_TATO['agent'])
plt.show()

"""#Ordenando datos para entrenar los modelos

### Se borran datos innecesarios y se manipulan NULLS para entrenamiento
"""

data_for_fit.drop(["country"], axis=1, inplace=True) #Se borra columnas con datos duplicados o no relevantes
data_for_fit.drop(["reservation_status"], axis=1, inplace=True) #Se borra columnas con datos duplicados o no relevantes
data_for_fit.drop(["reservation_status_date"], axis=1, inplace=True) #Se borra columnas con datos duplicados o no relevantes
data_for_fit.drop(["reserved_room_type"], axis=1, inplace=True) #Se borra columnas con datos duplicados o no relevantes
data_for_fit.drop(["assigned_room_type"], axis=1, inplace=True) #Se borra columnas con datos duplicados o no relevantes
data_for_fit['stays']= data_for_fit['stays_in_weekend_nights']+data_for_fit['stays_in_week_nights'] #Se unifican las columnas de estadía
data_for_fit.drop(["stays_in_weekend_nights","stays_in_week_nights"], axis=1, inplace=True) #Se borra columnas con datos duplicados o no relevantes
data_for_fit.drop(columns=["arrival_date_year","arrival_date_week_number","arrival_date_day_of_month","required_car_parking_spaces"], inplace=True)


data_for_fit['children'].replace('NA', 0, inplace=True) # Se considera importante esta columna, por lo que los NA se reemplaza por ceros. (Se entiende que al no estar relleno, no tienen hijos)
data_for_fit.fillna(value = 0, inplace=True) #Se consideran importantes los Null, ya que corresponden a reservas no realizadas por agencias.

# Inspeccionando
data_for_fit.info()

# Selección de datos para entrenamientos
y = data_for_fit["is_canceled"]
X = data_for_fit.drop(columns=["is_canceled"])

# Se realiza split en train, validation y test
X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1409)
X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, stratify=y_trainval , random_state=1409)

X_train.reset_index(drop=True, inplace=True)
X_test.reset_index(drop=True, inplace=True)
y_train.reset_index(drop=True, inplace=True)
y_test.reset_index(drop=True, inplace=True)
X_trainval.reset_index(drop=True, inplace=True)
y_trainval.reset_index(drop=True, inplace=True)
y_val.reset_index(drop=True, inplace=True)
X_val.reset_index(drop=True, inplace=True)

# Se valida si la cantidad de datos estan correctos
print(X_train.shape, X_val.shape, X_test.shape, X.shape)

"""##X_trainval"""

data_for_fit.info()

# Se utiliza One hot enconder porque se consideran importantes todas las categorías de seleccionadas.
ohe_all = OneHotEncoder(sparse_output=False)
enc_all = ohe_all.fit_transform(X_trainval[["hotel", "arrival_date_month","meal","Continent","market_segment","distribution_channel","customer_type"]])
df_enc_all = pd.DataFrame(data=enc_all, columns=ohe_all.get_feature_names_out())

"""##X_train

"""

# Se utiliza Transform para utilizar los parametros fitteados en X_trainval
enc_allxtrain = ohe_all.transform(X_train[["hotel", "arrival_date_month","meal","Continent","market_segment","distribution_channel","customer_type"]])
df_enc_alltrain = pd.DataFrame(data=enc_allxtrain, columns=ohe_all.get_feature_names_out())

"""X_val"""

# Se utiliza Transform para utilizar los parametros fitteados en X_trainval
enc_allxval = ohe_all.transform(X_val[["hotel", "arrival_date_month","meal","Continent","market_segment","distribution_channel","customer_type"]])
df_enc_allval = pd.DataFrame(data=enc_allxval, columns=ohe_all.get_feature_names_out())

# Se borran las columnas fitteadas y no relevantes
X_trainval.drop(columns=["hotel", "arrival_date_month","country_name","meal","Continent","market_segment","distribution_channel","customer_type"], inplace=True)
X_train.drop(columns=["hotel", "arrival_date_month","country_name","meal","Continent","market_segment","distribution_channel","customer_type"], inplace=True)
X_val.drop(columns=["hotel", "arrival_date_month","country_name","meal","Continent","market_segment","distribution_channel","customer_type"], inplace=True)

# Se agregan las columnas codificadas
X_trainval = pd.concat([X_trainval, df_enc_all], axis=1)
X_train = pd.concat([X_train, df_enc_alltrain], axis=1)
X_val = pd.concat([X_val, df_enc_allval], axis=1)
X_trainval.fillna(value = 0, inplace=True)
X_train.fillna(value = 0, inplace=True)
X_val.fillna(value = 0, inplace=True)


# Inspeccionando
X_train.info()

"""##X_test"""

# Se utiliza Transform para utilizar los parametros fitteados en X_trainval
enc_alltest = ohe_all.transform(X_test[["hotel", "arrival_date_month","meal","Continent","market_segment","distribution_channel","customer_type"]])
df_enc_alltest = pd.DataFrame(data=enc_alltest, columns=ohe_all.get_feature_names_out())

X_test.drop(columns=["hotel", "arrival_date_month","meal","country_name","Continent","market_segment","distribution_channel","customer_type"], inplace=True)

# Se agregan las columnas codificadas
X_test = pd.concat([X_test, df_enc_alltest, ], axis=1)

# Inspeccionando
X_test.info()

# Verificando si la cantidad de datos es correcta
print(X_train.shape, X_val.shape, X_test.shape, X.shape)

"""###Evaluando con KNN"""

# Se define hiperparámetros
Ks = [1, 2, 3, 4, 5, 10, 20]

df_metricsKnn = pd.DataFrame()

# Prueba de varios hiperparámetros
for k in Ks:
    knn_model = KNeighborsClassifier(n_neighbors = k)
    knn_model.fit(X_train, y_train)

    # Se generan predicciones
    preds_val = knn_model.predict(X_val)
    f1_val = f1_score(y_val, preds_val)
    preds_train = knn_model.predict(X_test)
    f1_train = f1_score(y_test, preds_train)

    # Resultados
    df_resultsknn = pd.DataFrame({"k": [k], "f1_train": [f1_train] ,"f1_val": [f1_val]})
    df_metricsKnn = pd.concat([df_metricsKnn, df_resultsknn])

df_metricsKnn

"""Se obtienen mejores resultados con 1 solo vecino, y en la medida que aumentamos la cantidad de vecinos, el resultado empeora.
Se valida en todo el DF
"""

knn_classifier = KNeighborsClassifier(n_neighbors=1)
knn_classifier.fit(X_trainval, y_trainval)

y_pred = knn_classifier.predict(X_test)

f1_score(y_test, y_pred)

"""## Evaluando con Random Forest"""

# Se define hiperparámetros
Rs = [2, 3, 5, 10, 50, 100, 200, 500, 1000]

df_metrics_random = pd.DataFrame()

# Prueba de varios hiperparámetros
for r in Rs:
    random_forest = RandomForestClassifier(n_estimators=r,max_depth=200,random_state=20)
    random_forest.fit(X_train, y_train)

    # Se generan predicciones
    preds_r = random_forest.predict(X_val)
    f1_valr = f1_score(y_val, preds_r)
    preds_trainr = random_forest.predict(X_test)
    f1_trainr = f1_score(y_test, preds_trainr)

    # Resultados
    df_results_random = pd.DataFrame({"r": [r], "f1_trainr": [f1_trainr] ,"f1_valr": [f1_valr]})
    df_metrics_random = pd.concat([df_metrics_random, df_results_random])

df_metrics_random

"""Se evalua con distinta cantidad de arboles, a medida que agregamos arboles el resultado mejora muy poco, pero al llegar a los 1000, el porcentaje de acertación comienza a bajar.
Se valida con 1000 arboles obteniendo casí los mismos resultados
"""

random_forest = RandomForestClassifier(n_estimators=1000,max_depth=200,random_state=20)
random_forest.fit(X_trainval, y_trainval)

rf_preds = random_forest.predict(X_test)

f1_score(y_test, rf_preds)

"""##Evaluando con Logistic Regression"""

# Se utiliza Standar scaler para intentar obtener mejores resultados
scaler = StandardScaler()
data_for_fit_scaled = scaler.fit_transform(X_trainval)


# Se utiliza el solver saga, según la documentación funciona mejor con grandes DF y se utiliza un max iter de 10000
logreg_model = LogisticRegression(solver='liblinear',max_iter=100, random_state=1409)
logreg_model.fit(X_trainval, y_trainval)

# Resultados
accuracy = logreg_model.score(X_test, y_test)
predlog = logreg_model.predict(X_test)
f1 = f1_score(y_test, predlog)
print(f'Accuracy del modelo : {accuracy:.4f}')
print(f'f1_score del modelo : {f1:.4f}')

logreg_model = LogisticRegression(random_state=14)
logreg_model.fit(X_trainval, y_trainval)

y_predlog = logreg_model.predict(X_test)

f1_score(y_test, y_predlog)

lr = LogisticRegression()
lr.fit(X_trainval, y_trainval)

y_pred_lr = lr.predict(X_test)

acc_lr = accuracy_score(y_test, y_pred_lr)
conf = confusion_matrix(y_test, y_pred_lr)
clf_report = classification_report(y_test, y_pred_lr)

print(f"Accuracy Score of Logistic Regression is : {acc_lr}")
print(f"Confusion Matrix : n{conf}")
print(f"Classification Report : n{clf_report}")

f1_score(y_test, y_pred_lr)

